{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring a Model\n",
    "\n",
    "When you've deployed a model into productipon as a service, you'll want to monitor it to track usage and explore the requests it processes. In this lab, you'll use Azure Application Insights to monitor activity for a model service endpoint.\n",
    "\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to work with gmalc-aml2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AKS Compute target\n",
    "\n",
    "You'll need to create an Azure Kubetrnetes Service (AKS) cluster to host the service. Run the following cell to do this.\n",
    "\n",
    "> **Note**: This can take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.....................................................................................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Cluster ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = 'aks-compute'\n",
    "\n",
    "try:\n",
    "    # get the cluster if it exists\n",
    "    production_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
    "    production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "production_cluster.wait_for_completion(show_output=True)\n",
    "print('Cluster ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Model for Deployment\n",
    "\n",
    "Now we need a model to deploy. Run the code below to:\n",
    "\n",
    "1. Create and register a dataset.\n",
    "2. Train a model using the dataset.\n",
    "3. Register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/diabetes.csv\n",
      "Uploading ./data/diabetes2.csv\n",
      "Uploaded ./data/diabetes2.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./data/diabetes.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Starting experiment: diabetes-training\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8988888888888888\n",
      "AUC: 0.8844128168352355\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from azureml.core import Dataset\n",
    "\n",
    "# Upload data files to the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'],\n",
    "                       target_path='diabetes-data/',\n",
    "                       overwrite=True,\n",
    "                       show_progress=True)\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore\n",
    "data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "# Register the tabular dataset\n",
    "data_set = data_set.register(workspace=ws, \n",
    "                           name='diabetes dataset',\n",
    "                           description='diabetes data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)\n",
    "\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = \"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = data_set.to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']},\n",
    "                   datasets=[('Training Data', data_set)])\n",
    "\n",
    "# Get the registered model\n",
    "model = ws.models['diabetes_model']\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model as a Web Service\n",
    "\n",
    "Now you're ready to deploy the registered model as a web service.\n",
    "\n",
    "First, create a folder for the deployment configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'diabetes_service'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need an entry script that the service will use to score new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/score_diabetes.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "#import azureml.train.automl # Required for AutoML models with pre-processing\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data - the features of patients to be classified.\n",
    "    data = json.loads(raw_data)['data']\n",
    "    print(data)\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    print(predictions)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also need a Conda configuration file for the service environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "#myenv.add_pip_package(\"azureml-sdk[automl]\") # Required for AutoML models\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the service to the AKS cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..................\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score_diabetes.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "aks_target = AksCompute(ws,'aks-compute')\n",
    "\n",
    "service_name = \"diabetes-service-aks\"\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "aks_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aks_target)\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the deployment has been successful and you can see a status of **Healthy**. If not, you can use the following code to check the status and get the service logs to help you troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "/bin/bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-12-16T20:04:33,547903143+00:00 - gunicorn/run \n",
      "2019-12-16T20:04:33,548679154+00:00 - rsyslog/run \n",
      "2019-12-16T20:04:33,549099960+00:00 - iot-server/run \n",
      "bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2019-12-16T20:04:33,556810869+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-12-16T20:04:33,645244823+00:00 - iot-server/finish 1 0\n",
      "2019-12-16T20:04:33,648866874+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-12-16 20:04:34,830 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\n",
      "    }\n",
      "}, switching offline: False\n",
      "2019-12-16 20:04:34,830 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-12-16 20:04:34,830 | azureml.core.model | DEBUG | version is None. Latest version is 18\n",
      "2019-12-16 20:04:34,830 | azureml.core.model | DEBUG | Found model path at azureml-models/diabetes_model/18/diabetes_model.pkl\n",
      "/azureml-envs/azureml_2ec026640b47025e72b68c7988b68c83/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(aks_service.state)\n",
    "print(aks_service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Application Insights\n",
    "\n",
    "Next, you need to enable Application Insights for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable AppInsights\n",
    "aks_service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Web Service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the URL to which these applications must submit their requests, and the authorization key they need to provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://13.82.134.135:80/api/v1/service/diabetes-service-aks/score\n",
      "ahPZr8XPQEJd81pb4vzxYwIlzlG73eQc\n"
     ]
    }
   ],
   "source": [
    "endpoint = aks_service.scoring_uri\n",
    "print(endpoint)\n",
    "primary, secondary = aks_service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "headers['Authorization'] = f'Bearer {primary}'\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "print(predictions)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go query Application Insights in the portal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
